Abstract

Gig-work platforms such as Uber, Swiggy, and Ola rely on opaque algorithmic systems to determine task assignment, pricing, and incentives, leaving workers unable to understand pay fluctuations, sudden drops in task availability, or silent policy changes. This lack of transparency creates financial uncertainty and an unequal power dynamic between platforms and workers. In this project, we propose a multilingual, worker-centric transparency system that infers and explains platform behaviour using only observable task and payment outcomes. Rather than attempting to replicate or access proprietary algorithms, the system analyzes location, time, distance, duration, and fare patterns to estimate assignment likelihood, earnings stability, and incentive activity at a zone level. Using a simulated opaque platform environment, we model hidden assignment, pay, and adaptive behaviours to evaluate the systemâ€™s ability to detect undocumented platform changes and potential disparities across workers or regions. The results are presented through an interactive, map-based web interface that uses intuitive visual cues and plain-language explanations to communicate risks, trends, and behavioural shifts. This approach demonstrates how opaque algorithmic decision-making in gig platforms can be made interpretable and actionable for workers, supporting transparency, fairness assessment, and informed decision-making without requiring access to platform internals.
